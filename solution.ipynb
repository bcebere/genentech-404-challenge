{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248b1567",
   "metadata": {},
   "source": [
    "# Genentech â€“ 404 Challenge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38571eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0c9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "workspace = Path(\"workspace\")\n",
    "results_dir = Path(\"results\")\n",
    "data_dir = Path(\"data\")\n",
    "\n",
    "workspace.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Consider a feature as categorical if there are at most <cat_limit> unique values for that feature\n",
    "cat_limit = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e19ce",
   "metadata": {},
   "source": [
    "## Load and augment data\n",
    "\n",
    "For each csv:\n",
    "1. Sort the dataset around the tuple __(\"RID_HASH\", \"VISCODE\")__.\n",
    "2. __Augment__ each row some temporal details: __total known visits__ and the __last known visit__.\n",
    "3. Using a MinMaxScaler, scale the columns [\"MMSE\", \"ADAS13\", \"Ventricles\", \"Hippocampus\", \"WholeBrain\", \"Entorhinal\", \"Fusiform\", \"MidTemp\"]. While this initially was for the NN experiments, it also helped some linear models in the longitudinal imputation.\n",
    "\n",
    "While the visits are not complete in the test set, adding the total visits and last known visit improved the public score.\n",
    "\n",
    "\n",
    "----\n",
    "Other failed approaches to augment the dataset include:\n",
    "- Learn a latent space using an RNN, LSTM, or Transformer, - from each row and its missingness mask -  and append it to each row. \n",
    "- Add details related to trends from [Ventricles, Hippocampus,WholeBrain, Entorhinal, Fusiform, MidTemp].\n",
    "\n",
    "While these approaches might help in a forecasting problem, they didn't improve the imputation error here. \n",
    "\n",
    "The latent space isn't trivial to model with missing values, and the neural net seemed to overfit the `dev_set,` leading to a poor score in the test data. The trends didn't help either, as the missingness mangled them. \n",
    "\n",
    "These additional experiments are not included here for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b692e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_base_dataset(df):\n",
    "    \"\"\"For each patient(RID_HASH), add some information from the other visits,\n",
    "    like the total known visits, and the last visit.\n",
    "    \"\"\"\n",
    "    for rid in df[\"RID_HASH\"].unique():\n",
    "        visits = len(df[df[\"RID_HASH\"] == rid])\n",
    "        last_visit = df[df[\"RID_HASH\"] == rid][\"VISCODE\"].max()\n",
    "\n",
    "        df.loc[df[\"RID_HASH\"] == rid, \"total_visits\"] = visits\n",
    "        df.loc[df[\"RID_HASH\"] == rid, \"last_visit\"] = last_visit\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def dataframe_hash(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Dataframe hashing, used for caching/backups\"\"\"\n",
    "    cols = sorted(list(df.columns))\n",
    "    return str(abs(pd.util.hash_pandas_object(df[cols].fillna(0)).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e87298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID_HASH</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER_num</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>DX_num</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>last_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...</td>\n",
       "      <td>0</td>\n",
       "      <td>79.1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.071871</td>\n",
       "      <td>0.548646</td>\n",
       "      <td>0.376516</td>\n",
       "      <td>0.464021</td>\n",
       "      <td>0.194906</td>\n",
       "      <td>0.400709</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...</td>\n",
       "      <td>6</td>\n",
       "      <td>79.6</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.237397</td>\n",
       "      <td>0.071956</td>\n",
       "      <td>0.548307</td>\n",
       "      <td>0.366398</td>\n",
       "      <td>0.403880</td>\n",
       "      <td>0.193367</td>\n",
       "      <td>0.397291</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.142655</td>\n",
       "      <td>0.525169</td>\n",
       "      <td>0.235599</td>\n",
       "      <td>0.513404</td>\n",
       "      <td>0.356253</td>\n",
       "      <td>0.294774</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>6</td>\n",
       "      <td>73.4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.144729</td>\n",
       "      <td>0.549210</td>\n",
       "      <td>0.230361</td>\n",
       "      <td>0.435097</td>\n",
       "      <td>0.322395</td>\n",
       "      <td>0.294175</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>12</td>\n",
       "      <td>73.9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.155550</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>0.215944</td>\n",
       "      <td>0.487831</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.277552</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...</td>\n",
       "      <td>60</td>\n",
       "      <td>79.8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.223699</td>\n",
       "      <td>0.170895</td>\n",
       "      <td>0.357020</td>\n",
       "      <td>0.321346</td>\n",
       "      <td>0.310935</td>\n",
       "      <td>0.399047</td>\n",
       "      <td>0.461476</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...</td>\n",
       "      <td>102</td>\n",
       "      <td>83.3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.168904</td>\n",
       "      <td>0.178231</td>\n",
       "      <td>0.352043</td>\n",
       "      <td>0.309095</td>\n",
       "      <td>0.256790</td>\n",
       "      <td>0.372685</td>\n",
       "      <td>0.416478</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.416382</td>\n",
       "      <td>0.602438</td>\n",
       "      <td>0.636654</td>\n",
       "      <td>0.610229</td>\n",
       "      <td>0.743037</td>\n",
       "      <td>0.624631</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>12</td>\n",
       "      <td>73.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.155205</td>\n",
       "      <td>0.398451</td>\n",
       "      <td>0.608521</td>\n",
       "      <td>0.634650</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.729087</td>\n",
       "      <td>0.638477</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>24</td>\n",
       "      <td>74.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.439698</td>\n",
       "      <td>0.598002</td>\n",
       "      <td>0.624603</td>\n",
       "      <td>0.624339</td>\n",
       "      <td>0.719605</td>\n",
       "      <td>0.639374</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4101 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               RID_HASH  VISCODE   AGE  \\\n",
       "2163  001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...        0  79.1   \n",
       "154   001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...        6  79.6   \n",
       "1385  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...        0  72.9   \n",
       "2698  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...        6  73.4   \n",
       "2291  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...       12  73.9   \n",
       "...                                                 ...      ...   ...   \n",
       "2895  ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...       60  79.8   \n",
       "2646  ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...      102  83.3   \n",
       "1962  ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...        0  72.1   \n",
       "122   ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...       12  73.1   \n",
       "1802  ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...       24  74.1   \n",
       "\n",
       "      PTGENDER_num  PTEDUCAT  DX_num  APOE4  CDRSB      MMSE    ADAS13  \\\n",
       "2163             0        20     1.0    1.0    0.5  0.923077  0.164384   \n",
       "154              0        20     1.0    1.0    1.5  0.923077  0.237397   \n",
       "1385             1        12     1.0    1.0    1.0  1.000000  0.123288   \n",
       "2698             1        12     1.0    1.0    1.0  1.000000  0.164384   \n",
       "2291             1        12     1.0    1.0    1.0  0.961538  0.109589   \n",
       "...            ...       ...     ...    ...    ...       ...       ...   \n",
       "2895             1        19     1.0    0.0    3.0  0.923077  0.223699   \n",
       "2646             1        19     1.0    0.0    3.0  0.846154  0.168904   \n",
       "1962             0        12     1.0    0.0    0.5  0.884615  0.150685   \n",
       "122              0        12     1.0    0.0    1.0  0.961538  0.155205   \n",
       "1802             0        12     1.0    0.0    1.0  0.846154  0.150685   \n",
       "\n",
       "      Ventricles  Hippocampus  WholeBrain  Entorhinal  Fusiform   MidTemp  \\\n",
       "2163    0.071871     0.548646    0.376516    0.464021  0.194906  0.400709   \n",
       "154     0.071956     0.548307    0.366398    0.403880  0.193367  0.397291   \n",
       "1385    0.142655     0.525169    0.235599    0.513404  0.356253  0.294774   \n",
       "2698    0.144729     0.549210    0.230361    0.435097  0.322395  0.294175   \n",
       "2291    0.155550     0.527878    0.215944    0.487831  0.342600  0.277552   \n",
       "...          ...          ...         ...         ...       ...       ...   \n",
       "2895    0.170895     0.357020    0.321346    0.310935  0.399047  0.461476   \n",
       "2646    0.178231     0.352043    0.309095    0.256790  0.372685  0.416478   \n",
       "1962    0.416382     0.602438    0.636654    0.610229  0.743037  0.624631   \n",
       "122     0.398451     0.608521    0.634650    0.617108  0.729087  0.638477   \n",
       "1802    0.439698     0.598002    0.624603    0.624339  0.719605  0.639374   \n",
       "\n",
       "      total_visits  last_visit  \n",
       "2163           2.0         6.0  \n",
       "154            2.0         6.0  \n",
       "1385           6.0        60.0  \n",
       "2698           6.0        60.0  \n",
       "2291           6.0        60.0  \n",
       "...            ...         ...  \n",
       "2895           7.0       102.0  \n",
       "2646           7.0       102.0  \n",
       "1962           3.0        24.0  \n",
       "122            3.0        24.0  \n",
       "1802           3.0        24.0  \n",
       "\n",
       "[4101 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set = pd.read_csv(data_dir / \"dev_set.csv\")\n",
    "dev_set = dev_set.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "dev_set = augment_base_dataset(dev_set)\n",
    "\n",
    "scaled_cols = [\n",
    "    \"MMSE\",\n",
    "    \"ADAS13\",\n",
    "    \"Ventricles\",\n",
    "    \"Hippocampus\",\n",
    "    \"WholeBrain\",\n",
    "    \"Entorhinal\",\n",
    "    \"Fusiform\",\n",
    "    \"MidTemp\",\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler().fit(dev_set[scaled_cols])\n",
    "dev_set[scaled_cols] = scaler.transform(dev_set[scaled_cols])\n",
    "\n",
    "dev_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a07f908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID_HASH</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER_num</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>DX_num</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>last_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...</td>\n",
       "      <td>6</td>\n",
       "      <td>79.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.237397</td>\n",
       "      <td>0.071956</td>\n",
       "      <td>0.548307</td>\n",
       "      <td>0.366398</td>\n",
       "      <td>0.403880</td>\n",
       "      <td>0.193367</td>\n",
       "      <td>0.397291</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525169</td>\n",
       "      <td>0.235599</td>\n",
       "      <td>0.513404</td>\n",
       "      <td>0.356253</td>\n",
       "      <td>0.294774</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549210</td>\n",
       "      <td>0.230361</td>\n",
       "      <td>0.435097</td>\n",
       "      <td>0.322395</td>\n",
       "      <td>0.294175</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>0.215944</td>\n",
       "      <td>0.487831</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.277552</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...</td>\n",
       "      <td>60</td>\n",
       "      <td>79.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...</td>\n",
       "      <td>102</td>\n",
       "      <td>83.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.178231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.309095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.416382</td>\n",
       "      <td>0.602438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610229</td>\n",
       "      <td>0.743037</td>\n",
       "      <td>0.624631</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>12</td>\n",
       "      <td>73.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.155205</td>\n",
       "      <td>0.398451</td>\n",
       "      <td>0.608521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.729087</td>\n",
       "      <td>0.638477</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>24</td>\n",
       "      <td>74.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.439698</td>\n",
       "      <td>0.598002</td>\n",
       "      <td>0.624603</td>\n",
       "      <td>0.624339</td>\n",
       "      <td>0.719605</td>\n",
       "      <td>0.639374</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4101 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               RID_HASH  VISCODE   AGE  \\\n",
       "2163  001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...        0   NaN   \n",
       "154   001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...        6  79.6   \n",
       "1385  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...        0   NaN   \n",
       "2698  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...        6   NaN   \n",
       "2291  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...       12   NaN   \n",
       "...                                                 ...      ...   ...   \n",
       "2895  ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...       60  79.8   \n",
       "2646  ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...      102  83.3   \n",
       "1962  ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...        0  72.1   \n",
       "122   ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...       12  73.1   \n",
       "1802  ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...       24  74.1   \n",
       "\n",
       "      PTGENDER_num  PTEDUCAT  DX_num  APOE4  CDRSB      MMSE    ADAS13  \\\n",
       "2163           0.0      20.0     1.0    1.0    0.5  0.923077  0.164384   \n",
       "154            0.0      20.0     1.0    1.0    1.5  0.923077  0.237397   \n",
       "1385           1.0      12.0     NaN    1.0    NaN       NaN       NaN   \n",
       "2698           1.0      12.0     NaN    1.0    NaN       NaN       NaN   \n",
       "2291           1.0      12.0     NaN    1.0    NaN       NaN       NaN   \n",
       "...            ...       ...     ...    ...    ...       ...       ...   \n",
       "2895           1.0      19.0     NaN    0.0    NaN       NaN       NaN   \n",
       "2646           1.0      19.0     NaN    0.0    NaN       NaN       NaN   \n",
       "1962           NaN      12.0     1.0    0.0    0.5  0.884615  0.150685   \n",
       "122            NaN      12.0     1.0    0.0    1.0  0.961538  0.155205   \n",
       "1802           0.0      12.0     1.0    0.0    1.0  0.846154  0.150685   \n",
       "\n",
       "      Ventricles  Hippocampus  WholeBrain  Entorhinal  Fusiform   MidTemp  \\\n",
       "2163         NaN          NaN    0.376516         NaN       NaN       NaN   \n",
       "154     0.071956     0.548307    0.366398    0.403880  0.193367  0.397291   \n",
       "1385         NaN     0.525169    0.235599    0.513404  0.356253  0.294774   \n",
       "2698         NaN     0.549210    0.230361    0.435097  0.322395  0.294175   \n",
       "2291         NaN     0.527878    0.215944    0.487831  0.342600  0.277552   \n",
       "...          ...          ...         ...         ...       ...       ...   \n",
       "2895    0.170895          NaN    0.321346         NaN       NaN       NaN   \n",
       "2646    0.178231          NaN    0.309095         NaN       NaN       NaN   \n",
       "1962    0.416382     0.602438         NaN    0.610229  0.743037  0.624631   \n",
       "122     0.398451     0.608521         NaN    0.617108  0.729087  0.638477   \n",
       "1802    0.439698     0.598002    0.624603    0.624339  0.719605  0.639374   \n",
       "\n",
       "      total_visits  last_visit  \n",
       "2163           2.0         6.0  \n",
       "154            2.0         6.0  \n",
       "1385           6.0        60.0  \n",
       "2698           6.0        60.0  \n",
       "2291           6.0        60.0  \n",
       "...            ...         ...  \n",
       "2895           7.0       102.0  \n",
       "2646           7.0       102.0  \n",
       "1962           3.0        24.0  \n",
       "122            3.0        24.0  \n",
       "1802           3.0        24.0  \n",
       "\n",
       "[4101 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_1 = pd.read_csv(data_dir / \"dev_1.csv\")\n",
    "dev_1 = dev_1.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "dev_1 = augment_base_dataset(dev_1)\n",
    "dev_1[scaled_cols] = scaler.transform(dev_1[scaled_cols])\n",
    "\n",
    "dev_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbda91b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID_HASH</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER_num</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>DX_num</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>last_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...</td>\n",
       "      <td>0</td>\n",
       "      <td>79.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.071871</td>\n",
       "      <td>0.548646</td>\n",
       "      <td>0.376516</td>\n",
       "      <td>0.464021</td>\n",
       "      <td>0.194906</td>\n",
       "      <td>0.400709</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...</td>\n",
       "      <td>6</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071956</td>\n",
       "      <td>0.548307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403880</td>\n",
       "      <td>0.193367</td>\n",
       "      <td>0.397291</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.142655</td>\n",
       "      <td>0.525169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513404</td>\n",
       "      <td>0.356253</td>\n",
       "      <td>0.294774</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435097</td>\n",
       "      <td>0.322395</td>\n",
       "      <td>0.294175</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.223699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310935</td>\n",
       "      <td>0.399047</td>\n",
       "      <td>0.461476</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.168904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.256790</td>\n",
       "      <td>0.372685</td>\n",
       "      <td>0.416478</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416382</td>\n",
       "      <td>0.602438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610229</td>\n",
       "      <td>0.743037</td>\n",
       "      <td>0.624631</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4101 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               RID_HASH  VISCODE   AGE  \\\n",
       "2163  001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...        0  79.1   \n",
       "154   001c7955017f905ccf78d55c94e81070a1cca7b1efb5bd...        6  79.6   \n",
       "1385  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...        0  72.9   \n",
       "2698  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...        6   NaN   \n",
       "2291  00e6fb56250581a8c8b5133f91443dd8c037e3cd8d0ba8...       12   NaN   \n",
       "...                                                 ...      ...   ...   \n",
       "2895  ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...       60   NaN   \n",
       "2646  ff59785f0d6b12fc51a07f09bb3a02790e54d04bb0803b...      102   NaN   \n",
       "1962  ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...        0  72.1   \n",
       "122   ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...       12   NaN   \n",
       "1802  ff98c50c3e97b776ab61db883cf1c8fd5a6d304d7165c8...       24   NaN   \n",
       "\n",
       "      PTGENDER_num  PTEDUCAT  DX_num  APOE4  CDRSB      MMSE    ADAS13  \\\n",
       "2163           0.0      20.0     1.0    1.0    0.5  0.923077  0.164384   \n",
       "154            NaN       NaN     NaN    1.0    NaN       NaN       NaN   \n",
       "1385           NaN      12.0     1.0    1.0    1.0  1.000000  0.123288   \n",
       "2698           NaN      12.0     1.0    1.0    1.0  1.000000  0.164384   \n",
       "2291           NaN      12.0     1.0    1.0    1.0  0.961538  0.109589   \n",
       "...            ...       ...     ...    ...    ...       ...       ...   \n",
       "2895           NaN      19.0     1.0    0.0    3.0  0.923077  0.223699   \n",
       "2646           NaN      19.0     1.0    0.0    3.0  0.846154  0.168904   \n",
       "1962           NaN      12.0     NaN    0.0    NaN       NaN       NaN   \n",
       "122            NaN      12.0     NaN    0.0    NaN       NaN       NaN   \n",
       "1802           0.0      12.0     NaN    0.0    NaN       NaN       NaN   \n",
       "\n",
       "      Ventricles  Hippocampus  WholeBrain  Entorhinal  Fusiform   MidTemp  \\\n",
       "2163    0.071871     0.548646    0.376516    0.464021  0.194906  0.400709   \n",
       "154     0.071956     0.548307         NaN    0.403880  0.193367  0.397291   \n",
       "1385    0.142655     0.525169         NaN    0.513404  0.356253  0.294774   \n",
       "2698         NaN     0.549210         NaN    0.435097  0.322395  0.294175   \n",
       "2291         NaN          NaN         NaN         NaN       NaN       NaN   \n",
       "...          ...          ...         ...         ...       ...       ...   \n",
       "2895         NaN     0.357020         NaN    0.310935  0.399047  0.461476   \n",
       "2646         NaN     0.352043         NaN    0.256790  0.372685  0.416478   \n",
       "1962    0.416382     0.602438         NaN    0.610229  0.743037  0.624631   \n",
       "122          NaN          NaN         NaN         NaN       NaN       NaN   \n",
       "1802         NaN          NaN    0.624603         NaN       NaN       NaN   \n",
       "\n",
       "      total_visits  last_visit  \n",
       "2163           2.0         6.0  \n",
       "154            2.0         6.0  \n",
       "1385           6.0        60.0  \n",
       "2698           6.0        60.0  \n",
       "2291           6.0        60.0  \n",
       "...            ...         ...  \n",
       "2895           7.0       102.0  \n",
       "2646           7.0       102.0  \n",
       "1962           3.0        24.0  \n",
       "122            3.0        24.0  \n",
       "1802           3.0        24.0  \n",
       "\n",
       "[4101 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_2 = pd.read_csv(data_dir / \"dev_2.csv\")\n",
    "dev_2 = dev_2.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "dev_2 = augment_base_dataset(dev_2)\n",
    "dev_2[scaled_cols] = scaler.transform(dev_2[scaled_cols])\n",
    "\n",
    "dev_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a41853b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID_HASH</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER_num</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>DX_num</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>last_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>988b6137f4352c01e4b52790505caa0c3ec438f117000a...</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fb640cef87a6af00053e632140ce18f5722431bb92576b...</td>\n",
       "      <td>12</td>\n",
       "      <td>66.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.077671</td>\n",
       "      <td>0.145063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f24f78d62c90319b575dfb48a482159c4d0df14cb71530...</td>\n",
       "      <td>66</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.050274</td>\n",
       "      <td>0.559104</td>\n",
       "      <td>0.565102</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.641093</td>\n",
       "      <td>0.911086</td>\n",
       "      <td>0.866886</td>\n",
       "      <td>5.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>da4cbd3f09e8ddc87cc72e542d43f072e7df288face65e...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f665c6ee86356bdd135be03c61348607cabd64ed8433ba...</td>\n",
       "      <td>12</td>\n",
       "      <td>82.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.206872</td>\n",
       "      <td>0.353047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208289</td>\n",
       "      <td>0.188006</td>\n",
       "      <td>0.363489</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>51923c5d7573ef46aa9197cae78c3305abea5b3479331f...</td>\n",
       "      <td>6</td>\n",
       "      <td>83.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.252103</td>\n",
       "      <td>0.541648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454850</td>\n",
       "      <td>0.480663</td>\n",
       "      <td>0.479467</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>06407d9ec85d62cd38189108ddffec23822f421b3db357...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>e5015703a58ccd5582a46d9f4a779edf062d683f3ae873...</td>\n",
       "      <td>132</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.193712</td>\n",
       "      <td>0.533115</td>\n",
       "      <td>0.491958</td>\n",
       "      <td>0.513933</td>\n",
       "      <td>0.508464</td>\n",
       "      <td>0.573437</td>\n",
       "      <td>9.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>cf6ea2601bb119113371df79931cc3734b77218f734ad0...</td>\n",
       "      <td>12</td>\n",
       "      <td>82.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.272259</td>\n",
       "      <td>0.572799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597707</td>\n",
       "      <td>0.380480</td>\n",
       "      <td>0.361608</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>2df190d5c803b896a4220cb58f98456ece1aadbdb9e6b4...</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.296849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1328 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               RID_HASH  VISCODE   AGE  \\\n",
       "0     988b6137f4352c01e4b52790505caa0c3ec438f117000a...       24   NaN   \n",
       "1     fb640cef87a6af00053e632140ce18f5722431bb92576b...       12  66.4   \n",
       "2     f24f78d62c90319b575dfb48a482159c4d0df14cb71530...       66  74.5   \n",
       "3     da4cbd3f09e8ddc87cc72e542d43f072e7df288face65e...        0   NaN   \n",
       "4     f665c6ee86356bdd135be03c61348607cabd64ed8433ba...       12  82.7   \n",
       "...                                                 ...      ...   ...   \n",
       "1323  51923c5d7573ef46aa9197cae78c3305abea5b3479331f...        6  83.5   \n",
       "1324  06407d9ec85d62cd38189108ddffec23822f421b3db357...        0   NaN   \n",
       "1325  e5015703a58ccd5582a46d9f4a779edf062d683f3ae873...      132  83.0   \n",
       "1326  cf6ea2601bb119113371df79931cc3734b77218f734ad0...       12  82.4   \n",
       "1327  2df190d5c803b896a4220cb58f98456ece1aadbdb9e6b4...       36   NaN   \n",
       "\n",
       "      PTGENDER_num  PTEDUCAT  DX_num  APOE4  CDRSB      MMSE    ADAS13  \\\n",
       "0              NaN      18.0     NaN    0.0    NaN       NaN       NaN   \n",
       "1              1.0      18.0     1.0    1.0    1.5  0.961538  0.077671   \n",
       "2              0.0      14.0     0.0    0.0    0.0  0.961538  0.050274   \n",
       "3              NaN      16.0     0.0    0.0    0.0  1.000000  0.191781   \n",
       "4              NaN      13.0     NaN    1.0    NaN       NaN       NaN   \n",
       "...            ...       ...     ...    ...    ...       ...       ...   \n",
       "1323           NaN      18.0     1.0    0.0    2.5  0.846154  0.150685   \n",
       "1324           NaN      20.0     NaN    0.0    NaN       NaN       NaN   \n",
       "1325           0.0      20.0     0.0    1.0    0.0  0.961538  0.205479   \n",
       "1326           NaN      18.0     1.0    0.0    0.5  0.884615  0.205479   \n",
       "1327           NaN      18.0     2.0    0.0    3.5  1.000000  0.296849   \n",
       "\n",
       "      Ventricles  Hippocampus  WholeBrain  Entorhinal  Fusiform   MidTemp  \\\n",
       "0            NaN          NaN         NaN         NaN       NaN       NaN   \n",
       "1       0.145063          NaN    0.542904         NaN       NaN       NaN   \n",
       "2       0.559104     0.565102    0.753302    0.641093  0.911086  0.866886   \n",
       "3            NaN          NaN         NaN         NaN       NaN       NaN   \n",
       "4       0.206872     0.353047         NaN    0.208289  0.188006  0.363489   \n",
       "...          ...          ...         ...         ...       ...       ...   \n",
       "1323    0.252103     0.541648         NaN    0.454850  0.480663  0.479467   \n",
       "1324         NaN          NaN         NaN         NaN       NaN       NaN   \n",
       "1325    0.193712     0.533115    0.491958    0.513933  0.508464  0.573437   \n",
       "1326    0.272259     0.572799         NaN    0.597707  0.380480  0.361608   \n",
       "1327         NaN          NaN         NaN         NaN       NaN       NaN   \n",
       "\n",
       "      total_visits  last_visit  \n",
       "0              6.0        36.0  \n",
       "1              5.0        24.0  \n",
       "2              5.0        96.0  \n",
       "3              2.0        36.0  \n",
       "4              7.0        60.0  \n",
       "...            ...         ...  \n",
       "1323           5.0        60.0  \n",
       "1324           1.0         0.0  \n",
       "1325           9.0       132.0  \n",
       "1326           3.0        12.0  \n",
       "1327           8.0        72.0  \n",
       "\n",
       "[1328 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_A = pd.read_csv(data_dir / \"test_A.csv\")\n",
    "test_A = augment_base_dataset(test_A)\n",
    "test_A[scaled_cols] = scaler.transform(test_A[scaled_cols])\n",
    "\n",
    "test_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1bd252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID_HASH</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER_num</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>DX_num</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>last_visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90a4f1869cf459af5fe39e53f1c328540f1dcf5a1908f7...</td>\n",
       "      <td>60</td>\n",
       "      <td>67.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.069404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.330562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fad8ca8f903cf3ddf566926eabdb8718e8568962675519...</td>\n",
       "      <td>30</td>\n",
       "      <td>69.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.059315</td>\n",
       "      <td>0.162418</td>\n",
       "      <td>0.749086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.724619</td>\n",
       "      <td>0.481817</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d342fb7689e49c754709870c77e1aa3ed770dd193e9f9c...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5319e7ba149f0f81715b5e7f854036fc937141840bbd52...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430159</td>\n",
       "      <td>0.520727</td>\n",
       "      <td>0.415281</td>\n",
       "      <td>5.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6eef135d8c4eca67b0e130b8f4aedbc37a99938224d661...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605756</td>\n",
       "      <td>0.508509</td>\n",
       "      <td>0.629277</td>\n",
       "      <td>0.604379</td>\n",
       "      <td>0.449383</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>fbf6267bf7d92b507feb4957d7aa90ea5bb50893bb79d4...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497354</td>\n",
       "      <td>0.374770</td>\n",
       "      <td>0.460151</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>03e8ddc654f8e27332c5b09618b355d7f9529d614adb0f...</td>\n",
       "      <td>12</td>\n",
       "      <td>81.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.264134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1156748dfd6e69e1f364c31584e957d3b1ef656b898942...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>0c7e17c442e715e067bd472c1e472b4937914d7fb8d492...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.606563</td>\n",
       "      <td>0.458784</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>8b33cc9dd06fc18f130e185fdf1e6d657dbc80add9ff6e...</td>\n",
       "      <td>0</td>\n",
       "      <td>82.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218111</td>\n",
       "      <td>0.415124</td>\n",
       "      <td>0.437385</td>\n",
       "      <td>0.408995</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.585317</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               RID_HASH  VISCODE   AGE  \\\n",
       "0     90a4f1869cf459af5fe39e53f1c328540f1dcf5a1908f7...       60  67.9   \n",
       "1     fad8ca8f903cf3ddf566926eabdb8718e8568962675519...       30  69.1   \n",
       "2     d342fb7689e49c754709870c77e1aa3ed770dd193e9f9c...       12   NaN   \n",
       "3     5319e7ba149f0f81715b5e7f854036fc937141840bbd52...        6   NaN   \n",
       "4     6eef135d8c4eca67b0e130b8f4aedbc37a99938224d661...        0   NaN   \n",
       "...                                                 ...      ...   ...   \n",
       "1465  fbf6267bf7d92b507feb4957d7aa90ea5bb50893bb79d4...        0   NaN   \n",
       "1466  03e8ddc654f8e27332c5b09618b355d7f9529d614adb0f...       12  81.5   \n",
       "1467  1156748dfd6e69e1f364c31584e957d3b1ef656b898942...        0   NaN   \n",
       "1468  0c7e17c442e715e067bd472c1e472b4937914d7fb8d492...       12   NaN   \n",
       "1469  8b33cc9dd06fc18f130e185fdf1e6d657dbc80add9ff6e...        0  82.1   \n",
       "\n",
       "      PTGENDER_num  PTEDUCAT  DX_num  APOE4  CDRSB      MMSE    ADAS13  \\\n",
       "0              1.0      20.0     0.0    1.0    0.0  1.000000  0.123288   \n",
       "1              NaN      16.0     0.0    0.0    0.0  0.961538  0.059315   \n",
       "2              NaN      12.0     NaN    1.0    NaN       NaN       NaN   \n",
       "3              NaN      18.0     NaN    0.0    NaN       NaN       NaN   \n",
       "4              0.0      16.0     0.0    0.0    0.0  0.961538  0.095890   \n",
       "...            ...       ...     ...    ...    ...       ...       ...   \n",
       "1465           NaN      12.0     NaN    2.0    NaN       NaN       NaN   \n",
       "1466           0.0      15.0     NaN    0.0    NaN       NaN       NaN   \n",
       "1467           0.0      18.0     0.0    0.0    0.0  0.961538  0.136986   \n",
       "1468           NaN      16.0     NaN    0.0    NaN       NaN       NaN   \n",
       "1469           0.0      20.0     NaN    NaN    NaN       NaN       NaN   \n",
       "\n",
       "      Ventricles  Hippocampus  WholeBrain  Entorhinal  Fusiform   MidTemp  \\\n",
       "0       0.069404          NaN    0.330562         NaN       NaN       NaN   \n",
       "1       0.162418     0.749086         NaN    0.899471  0.724619  0.481817   \n",
       "2            NaN          NaN         NaN         NaN       NaN       NaN   \n",
       "3            NaN     0.476637         NaN    0.430159  0.520727  0.415281   \n",
       "4            NaN     0.605756    0.508509    0.629277  0.604379  0.449383   \n",
       "...          ...          ...         ...         ...       ...       ...   \n",
       "1465         NaN     0.492325         NaN    0.497354  0.374770  0.460151   \n",
       "1466    0.264134          NaN    0.208488         NaN       NaN       NaN   \n",
       "1467         NaN          NaN    0.686284         NaN       NaN       NaN   \n",
       "1468         NaN     0.553883         NaN    0.753086  0.606563  0.458784   \n",
       "1469    0.218111     0.415124    0.437385    0.408995  0.610237  0.585317   \n",
       "\n",
       "      total_visits  last_visit  \n",
       "0              6.0        60.0  \n",
       "1              3.0        30.0  \n",
       "2              1.0        12.0  \n",
       "3              5.0       126.0  \n",
       "4              5.0        72.0  \n",
       "...            ...         ...  \n",
       "1465           7.0        60.0  \n",
       "1466           3.0        12.0  \n",
       "1467           4.0        84.0  \n",
       "1468           4.0        42.0  \n",
       "1469           5.0        24.0  \n",
       "\n",
       "[1470 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_B = pd.read_csv(data_dir / \"test_B.csv\")\n",
    "test_B = augment_base_dataset(test_B)\n",
    "test_B[scaled_cols] = scaler.transform(test_B[scaled_cols])\n",
    "\n",
    "test_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e1626d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6b6a7136f42a8dbd469a201b88e2abb54a93667822761357db2f6d620da6af8a_0_Ventricles_test_A',\n",
       "       40613.0818580834], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(data_dir / \"sample_submission.csv\")\n",
    "\n",
    "submission.values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c23459",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "__Observations__:\n",
    "- While a time series problem, several patients have a single visit(255 in the training set), which must be handled as a static imputation problem.\n",
    "- Features [`RID_HASH`, `PTGENDER_num`, `PTEDUCAT`, `APOE4`] are constant by the patient and need special handling - we should not have multiple values by  `RID_HASH`.\n",
    "- There is a correlation between `VISCODE` and `AGE`, which must be respected. More precisely, 1 `VISCODE` step maps to 1 month. `VISCODE` = 6 maps to 6 months after the baseline visit.\n",
    "- `CDRSB` is a multiple of 0.5\n",
    "- `DX_NUM` and `MMSE` must be integers\n",
    "- `ADAS13` is multiple of 1/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf98b890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Visits\n",
       "2     289\n",
       "1     255\n",
       "3     206\n",
       "4     163\n",
       "5     128\n",
       "6      68\n",
       "7      45\n",
       "8      33\n",
       "9      23\n",
       "10     13\n",
       "11      2\n",
       "12      1\n",
       "Name: Patients count by visit count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_visit_counts(df):\n",
    "    \"\"\"Get the number of patients for each visit count, eg. patients with single visits, 2 visits etc.\"\"\"\n",
    "    out = df.groupby([\"RID_HASH\"]).count()[\"VISCODE\"].value_counts()\n",
    "    out.index = out.index.rename(\"Visits\")\n",
    "    out.name = \"Patients count by visit count\"\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# test_A\n",
    "# get_visit_counts(test_A)\n",
    "\n",
    "# test_B\n",
    "# get_visit_counts(test_B)\n",
    "\n",
    "# Train data\n",
    "get_visit_counts(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e5a5465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RID_HASH', 'PTGENDER_num', 'PTEDUCAT', 'APOE4', 'total_visits', 'last_visit']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_constants_by_patients(df):\n",
    "    \"\"\"Get constant feature by patient.\"\"\"\n",
    "    candidates = list(df.columns)\n",
    "    for rid in df[\"RID_HASH\"].unique():\n",
    "        patient = df[df[\"RID_HASH\"] == rid]\n",
    "        diffs = patient.drop(columns=[\"RID_HASH\"]).diff().fillna(0)\n",
    "\n",
    "        zeros = (diffs == 0).sum()\n",
    "\n",
    "        for col in zeros.index:\n",
    "            if zeros[col] != len(patient):\n",
    "                if col in candidates:\n",
    "                    candidates.remove(col)\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "get_constants_by_patients(dev_set)\n",
    "# get_constants_by_patients(test_A)\n",
    "# get_constants_by_patients(test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "001c0358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good. One VISCODE step maps to 1 month\n"
     ]
    }
   ],
   "source": [
    "def test_age_viscode_corr(df):\n",
    "    \"\"\"Test AGE - VISCODE relation.\"\"\"\n",
    "    candidates = list(df.columns)\n",
    "    for rid in df[\"RID_HASH\"].unique():\n",
    "        patient = df[df[\"RID_HASH\"] == rid]\n",
    "        age_diffs = patient[\"AGE\"].diff().fillna(0).values\n",
    "        viscode_diffs = patient[\"VISCODE\"].diff().fillna(0).values\n",
    "\n",
    "        assert np.allclose(12 * age_diffs, viscode_diffs)\n",
    "    print(\"All good. One VISCODE step maps to 1 month\")\n",
    "\n",
    "\n",
    "test_age_viscode_corr(dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05500c",
   "metadata": {},
   "source": [
    "## Iterative Horizontal(instance-wise) imputation\n",
    "\n",
    "We first define a method for instance-wise imputation: for a single patient visit, to impute the missing values from the observed values. \n",
    "\n",
    "This is especially valuable for patients with single visits, imputing static features(`PTGENDER`, `PTEDUCAT`), but also to seed the longitudinal imputation.\n",
    "\n",
    "For the task, we are using [__HyperImpute__](https://github.com/vanderschaarlab/hyperimpute), an iterative imputation algorithm, which generalizes MICE and missForest, by allowing any type of base learner(not just linear/random forest), and which uses AutoML to tune the models by column and by iteration.\n",
    "\n",
    "The pool of __base learners__ is: \n",
    " - classifiers: [`xgboost`, `catboost`, `logistic_regression`, `random_forest`, `lgbm`]\n",
    " - regressors: [`xgboost_regressor`, `catboost_regressor`, `linear_regression`, `random_forest_regressor`, `lgbm_regressor`]\n",
    "\n",
    "For selecting a classifier, the internal optimizer searches for the maximal AUCROC score obtained on the observed data(without any missing values). For selecting a regressor, the optimizer searches for the maximal R2 score obtained on the observed data.\n",
    "\n",
    "#### Model search\n",
    "The models are re-evaluated for each column and for for each imputation iteration. \n",
    "\n",
    "The following table contains a snippet from the test set from the first imputation iteration.\n",
    "For each target, we list the selected model to impute that column and its arguments.\n",
    "\n",
    "The evaluation score is the `AUCROC` for classifiers(with categorical targets), and `R2` for regressors.\n",
    "The evaluation is performed on observed data, and for each target column, we use the rest of the features from each patient. For example, for target \"AGE\", we benchmark a model trained on the patient features without the \"AGE\" column.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Target Column | Score on the observed data | Model   | Model parameters                                                                                                                                                                                                                                                                                                                           |\n",
    "|---------------|---------------------------------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| PTGENDER_num  | 0.9581                          | xgboost | { \t'reg_lambda': 5.047146750787419, \t'reg_alpha': 6.76511248668679, \t'colsample_bytree': 0.8104392038078263, \t'colsample_bynode': 0.8362908590082906, \t'colsample_bylevel': 0.8415650566586329, \t'subsample': 0.899881421386532, \t'lr': 0.001, \t'max_depth': 5, \t'n_estimators': 282, \t'min_child_weight': 6, \t'max_bin': 384, \t'grow_policy': 1 }     |\n",
    "| MidTemp       | 0.8257                          | xgboost_regressor | {'reg_lambda': 2.849409466197371, 'reg_alpha': 0.12666464008400558, 'lr': 0.001, 'colsample_bytree': 0.8435311327845306, 'colsample_bynode': 0.7146987739735369, 'colsample_bylevel': 0.6200355491527186, 'subsample': 0.5832358516941026, 'max_depth': 5, 'n_estimators': 299, 'min_child_weight': 7, 'max_bin': 354, 'grow_policy': 0}   |\n",
    "| PTEDUCAT      | 0.5983                          | xgboost_regressor | {'reg_lambda': 1.2043879741664179, 'reg_alpha': 0.43791636068939466, 'lr': 0.0001, 'colsample_bytree': 0.8787783651242453, 'colsample_bynode': 0.5585583183603081, 'colsample_bylevel': 0.8510294755051252, 'subsample': 0.8979610242164071, 'max_depth': 5, 'n_estimators': 295, 'min_child_weight': 5, 'max_bin': 435, 'grow_policy': 0} |\n",
    "| Hippocampus   | 0.8485                          | xgboost_regressor | {'reg_lambda': 4.089278739805318, 'reg_alpha': 0.17543671290431134, 'lr': 0.001, 'colsample_bytree': 0.8786337139809749, 'colsample_bynode': 0.8318946749900471, 'colsample_bylevel': 0.4180573427733283, 'subsample': 0.8994410403323976, 'max_depth': 5, 'n_estimators': 300, 'min_child_weight': 51, 'max_bin': 279, 'grow_policy': 0}  |\n",
    "| AGE           | 0.7392                          | xgboost_regressor | {'reg_lambda': 2.8968259886307823, 'reg_alpha': 2.689625820088316, 'lr': 0.0001, 'colsample_bytree': 0.7833585243779915, 'colsample_bynode': 0.7816022024981492, 'colsample_bylevel': 0.8547872455663319, 'subsample': 0.8598089876739611, 'max_depth': 5, 'n_estimators': 300, 'min_child_weight': 10, 'max_bin': 310, 'grow_policy': 1}  |\n",
    "| Ventricles    | 0.6632                          | xgboost_regressor | {'reg_lambda': 5.967189083549597, 'reg_alpha': 0.2808968422111205, 'lr': 0.01, 'colsample_bytree': 0.5217102570325618, 'colsample_bynode': 0.8804696194235598, 'colsample_bylevel': 0.8708840451006549, 'subsample': 0.8697548865770208, 'max_depth': 5, 'n_estimators': 274, 'min_child_weight': 15, 'max_bin': 476, 'grow_policy': 1}    |\n",
    "| APOE4         | 0.9273                          | xgboost | {'reg_lambda': 2.8690526199504927, 'reg_alpha': 3.522038047599354, 'colsample_bytree': 0.8424641257249423, 'colsample_bynode': 0.8665271329717139, 'colsample_bylevel': 0.5663182904186024, 'subsample': 0.7565978995769022, 'lr': 0.01, 'max_depth': 4, 'n_estimators': 204, 'min_child_weight': 3, 'max_bin': 276, 'grow_policy': 0}     |\n",
    "| WholeBrain    | 0.8409                          | xgboost_regressor | {'reg_lambda': 7.307980134321348, 'reg_alpha': 0.030638315290805348, 'lr': 0.001, 'colsample_bytree': 0.7045048629753644, 'colsample_bynode': 0.6717575448956548, 'colsample_bylevel': 0.8523579198631583, 'subsample': 0.811683946029976, 'max_depth': 4, 'n_estimators': 263, 'min_child_weight': 9, 'max_bin': 283, 'grow_policy': 1}   |\n",
    "| CDRSB         | 0.8647                          | xgboost_regressor | {'reg_lambda': 5.7188353890043215, 'reg_alpha': 1.5070276030155896, 'lr': 0.001, 'colsample_bytree': 0.8568652904045923, 'colsample_bynode': 0.8228490141313873, 'colsample_bylevel': 0.717485389358915, 'subsample': 0.838052956971084, 'max_depth': 5, 'n_estimators': 203, 'min_child_weight': 0, 'max_bin': 421, 'grow_policy': 0}     |\n",
    "| MMSE          | 0.7849                          | xgboost_regressor | {'reg_lambda': 4.411307527948391, 'reg_alpha': 0.31020731746278507, 'lr': 0.001, 'colsample_bytree': 0.8053955379772784, 'colsample_bynode': 0.6706019993671946, 'colsample_bylevel': 0.7185383704960561, 'subsample': 0.5333272846743093, 'max_depth': 5, 'n_estimators': 97, 'min_child_weight': 0, 'max_bin': 451, 'grow_policy': 1}    |\n",
    "| ADAS13        | 0.8387                          | xgboost_regressor | {'reg_lambda': 7.057171358250669, 'reg_alpha': 0.018439155294796027, 'lr': 0.001, 'colsample_bytree': 0.7706572341235782, 'colsample_bynode': 0.7583265692412863, 'colsample_bylevel': 0.6436305828182355, 'subsample': 0.6700622116024618, 'max_depth': 4, 'n_estimators': 276, 'min_child_weight': 12, 'max_bin': 341, 'grow_policy': 0} |\n",
    "| DX_num        | 0.9901                          | xgboost | {'reg_lambda': 3.491083476792939, 'reg_alpha': 0.4780607781520152, 'colsample_bytree': 0.7135088508567039, 'colsample_bynode': 0.7401906044406585, 'colsample_bylevel': 0.877133448906174, 'subsample': 0.6640341453442069, 'lr': 0.01, 'max_depth': 5, 'n_estimators': 284, 'min_child_weight': 0, 'max_bin': 476, 'grow_policy': 1}      |\n",
    "| Fusiform      | 0.7955                          | xgboost_regressor | {'reg_lambda': 7.283324221523343, 'reg_alpha': 0.02239137521568263, 'lr': 0.0001, 'colsample_bytree': 0.8142461647714889, 'colsample_bynode': 0.4828281981820367, 'colsample_bylevel': 0.8124281636754882, 'subsample': 0.5836904623813199, 'max_depth': 5, 'n_estimators': 300, 'min_child_weight': 8, 'max_bin': 451, 'grow_policy': 1}  |\n",
    "| Entorhinal    | 0.7384               | xgboost_regressor | {'reg_lambda': 8.488614432064912, 'reg_alpha': 0.21197074583337316, 'lr': 0.001, 'colsample_bytree': 0.8787074288786586, 'colsample_bynode': 0.8439109829757719, 'colsample_bylevel': 0.43614024854551137, 'subsample': 0.7445117791091113, 'max_depth': 5, 'n_estimators': 282, 'min_child_weight': 55, 'max_bin': 266, 'grow_policy': 1} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe91c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperimpute.logger as log\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "log.remove()\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "\n",
    "def horizontal_imputation(train_data, test_data):\n",
    "    imputed_test_data = test_data.copy()\n",
    "    imputer_kwargs = {\n",
    "        \"optimizer\": \"bayesian\",\n",
    "        \"classifier_seed\": [\n",
    "            \"xgboost\",\n",
    "            \"catboost\",\n",
    "            \"logistic_regression\",\n",
    "            \"random_forest\",\n",
    "        ],\n",
    "        \"regression_seed\": [\n",
    "            \"xgboost_regressor\",\n",
    "            \"catboost_regressor\",\n",
    "            \"linear_regression\",\n",
    "            \"random_forest_regressor\",\n",
    "        ],\n",
    "        \"select_lazy\": False,\n",
    "        \"optimize_thresh\": 10000,\n",
    "        \"class_threshold\": cat_limit,\n",
    "    }\n",
    "\n",
    "    imputer = Imputers().get(\n",
    "        \"hyperimpute\",\n",
    "        **imputer_kwargs,\n",
    "    )\n",
    "    imputation_input = pd.concat([train_data, test_data], ignore_index=True)\n",
    "    imputation_ids = imputation_input[\"RID_HASH\"]\n",
    "    imputation_input = imputation_input.drop(columns=[\"RID_HASH\"])\n",
    "\n",
    "    imputed_test_data = imputer.fit_transform(imputation_input)\n",
    "    imputed_test_data = imputed_test_data.tail(len(test_data))\n",
    "\n",
    "    out_cols = [\"RID_HASH\"] + list(imputed_test_data.columns)\n",
    "    imputed_test_data[\"RID_HASH\"] = test_data[\"RID_HASH\"].values\n",
    "\n",
    "    return imputed_test_data[out_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec929df",
   "metadata": {},
   "source": [
    "## Iterative Longitudinal imputation\n",
    "\n",
    "It is important for patients with multiple visits to impute constrained by other visits.\n",
    "\n",
    "`HyperImpute` is dedicated to static imputation, and cannot be used directly for this task.\n",
    "However, we can use its base learners for this task by preprocessing the data.\n",
    "\n",
    "#### Preprocessing\n",
    "Two sets of estimators are trained, __forward__ and __reverse__, for the direction in which we try to approximate a particular feature.\n",
    "\n",
    "For every target feature:\n",
    "- We retrieve the previous visit, given the direction we work in. For the direction __forward__, the previous visit is the previous `VISCODE`. For the direction __reverse__, the previous visit is the next `VISCODE`. \n",
    "- We generate a training set consisting of the previous visit, and the current visit without the target feature\n",
    "- The `prepare_temporal_data` function implements this strategy.\n",
    "\n",
    "#### Model Search\n",
    "The search pool consists of \"XGBoost\", \"CatBoost\", \"LGBM\", \"Random forest\", \"KNearestNeighbor\" and linear models.\n",
    "\n",
    "Similar to the Horizontal imputation setup, we run the AutoML logic on the preprocessed data, selecting the optimal AUCROC for classifiers and the optimal R2 score for regressors.\n",
    "\n",
    "The static features - `PTEDUCAT`, `PTGENDER`, `APOE4`, and the ones correlated with `VISCODE`(`AGE`), are not evaluted here.\n",
    "\n",
    "\n",
    "Selected Predictors for the __forward__ direction\n",
    "\n",
    "| Target Column | Score on the observed data | Model             | Model parameters                                                                                                                                                                                                                                                                                                                    |\n",
    "|---------------|---------------------------------|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| MidTemp       | 0.8511                          | ridge_regression | {}                                                                                                                                                                                                                                                                                                                                  |\n",
    "| Hippocampus   | 0.8693                          | xgboost_regressor | {'reg_lambda': 1.664443906152452, 'reg_alpha': 0.11216371454959836, 'max_depth': 4, 'n_estimators': 59, 'lr': 0.0001}                                                                                                                                                                                                               |\n",
    "| Ventricles    | 0.7916                          | ridge_regression |  {'max_iter': 100, 'solver': 1} # HyperImpute's defaults                                                                                                                                                                                                                                                                                                        |\n",
    "| WholeBrain    | 0.89219                         | ridge_regression | {'max_iter': 10000, 'solver': 1}                                                                                                                                                                                                                                                                                                                                  |\n",
    "| CDRSB         | 0.8235                          | ridge_regression | {'max_iter': 10000, 'solver': 1}                                                                                                                                                                                                                                                                                                                                  |\n",
    "| MMSE          | 0.7464                          | xgboost_regressor | {'reg_lambda': 2.1888371329742604, 'reg_alpha': 0.9312430343555846, 'max_depth': 2, 'n_estimators': 82, 'lr': 0.01}                                                                                                                                                                                                                 |\n",
    "| ADAS13        | 0.8184                          | ridge_regression | {}                                                                                                                                                                                                                                                                                                       |\n",
    "| DX_num        | 0.9877                          | xgboost           | {'reg_lambda': 8.962330859372681, 'reg_alpha': 8.608303558298164, 'colsample_bytree': 0.7745875968255177, 'colsample_bynode': 0.3990200802902815, 'colsample_bylevel': 0.8924327091878707, 'subsample': 0.8411533780703977, 'lr': 0.0001, 'max_depth': 3, 'n_estimators': 169, 'min_child_weight': 1, 'max_bin': 256, 'booster': 1} |\n",
    "| Fusiform      | 0.8196                          | ridge_regression | {'max_iter': 10000, 'solver': 1}                                                                                                                                                                                                                                                                                                                                  |\n",
    "| Entorhinal    | 0.71296                         | ridge_regression | {}                                                                                                                                                                                                                                                                                                                                  |\n",
    "\n",
    "\n",
    "Selected Predictors selected for the __reverse__ direction\n",
    "\n",
    "| Target Column | Score on the observed data | Model             | Model parameters                                                                                                                                                                                                                                                                                                                     |\n",
    "|---------------|---------------------------------|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| MidTemp       | 0.8541                          | ridge_regression | {'max_iter': 1000, 'solver': 1}                                                                                                                                                                                                                                                                                                                                   |\n",
    "| Hippocampus   | 0.8697                          | xgboost_regressor | {'reg_lambda': 0.8716130833968974, 'reg_alpha': 0.6316607826045982, 'max_depth': 4, 'n_estimators': 100, 'lr': 0.0001}                                                                                                                                                                                                               |\n",
    "| Ventricles    | 0.7414                          | ridge_regression | {'max_iter': 100, 'solver': 1}                                                                                                                                                                                                                                                                                                                                   |\n",
    "| WholeBrain    | 0.8917                          | ridge_regression | {'max_iter': 100, 'solver': 1}                                                                                                                                                                                                                                                                                                                                   |\n",
    "| CDRSB         | 0.8143                          | xgboost_regressor | {'reg_lambda': 4.0066164445274195, 'reg_alpha': 5.238168400540354, 'max_depth': 2, 'n_estimators': 86, 'lr': 0.0001}                                                                                                                                                                                                                 |\n",
    "| MMSE          | 0.7416                          | xgboost_regressor | {'reg_lambda': 6.668953586033021, 'reg_alpha': 0.690722830428056, 'max_depth': 2, 'n_estimators': 75, 'lr': 0.01}                                                                                                                                                                                                                    |\n",
    "| ADAS13        | 0.8200                          | xgboost_regressor | {'reg_lambda': 3.3543843807030633, 'reg_alpha': 0.5623126283166717, 'max_depth': 3, 'n_estimators': 78, 'lr': 0.0001}                                                                                                                                                                                                                |\n",
    "| DX_num        | 0.9834                          | xgboost           | {'reg_lambda': 9.581894273376596, 'reg_alpha': 3.996895430038997, 'colsample_bytree': 0.41805003542171487, 'colsample_bynode': 0.8056647613216464, 'colsample_bylevel': 0.6632455401989068, 'subsample': 0.7898718692552386, 'lr': 0.0001, 'max_depth': 5, 'n_estimators': 224, 'min_child_weight': 0, 'max_bin': 503, 'booster': 1} |\n",
    "| Fusiform      | 0.8207                          | ridge_regression | {'max_iter': 1000, 'solver': 1}                                                                                                                                                                                                                                                                                                                                   |\n",
    "| Entorhinal    | 0.7069                          | ridge_regression | {'max_iter': 100, 'solver': 1}                                                                                                                                                                                                                                                                                                                                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a300d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "from hyperimpute.plugins.prediction import Classifiers, Regression\n",
    "from hyperimpute.utils.optimizer import EarlyStoppingExceeded, create_study\n",
    "from hyperimpute.utils.tester import evaluate_estimator, evaluate_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_cols = list(dev_set.drop(columns=[\"RID_HASH\"]).columns)\n",
    "\n",
    "eval_cols = [\n",
    "    \"DX_num\",\n",
    "    \"CDRSB\",\n",
    "    \"MMSE\",\n",
    "    \"ADAS13\",\n",
    "    \"Ventricles\",\n",
    "    \"Hippocampus\",\n",
    "    \"WholeBrain\",\n",
    "    \"Entorhinal\",\n",
    "    \"Fusiform\",\n",
    "    \"MidTemp\",\n",
    "]\n",
    "\n",
    "\n",
    "def prepare_temporal_data(data, target_col: str, direction: str):\n",
    "    target_train_data = []\n",
    "    target_train_labels = []\n",
    "\n",
    "    for item in data.groupby(\"RID_HASH\"):\n",
    "        local = item[1]\n",
    "        local = local.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "\n",
    "        rid = local[\"RID_HASH\"]\n",
    "\n",
    "        prev_cols = [f\"prev_{col}\" for col in train_cols]\n",
    "        prev_row = np.zeros(len(prev_cols))\n",
    "\n",
    "        if direction == \"forward\":\n",
    "            rows = local.iterrows()\n",
    "        else:\n",
    "            rows = local.iloc[::-1].iterrows()\n",
    "\n",
    "        for idx, row in rows:\n",
    "            target_val = row[target_col]\n",
    "            tmp_row = row[train_cols].copy()\n",
    "            src_data = tmp_row.to_frame().T.drop(columns=[target_col])\n",
    "\n",
    "            src_data[prev_cols] = prev_row\n",
    "\n",
    "            prev_row = tmp_row\n",
    "\n",
    "            target_train_data.append(src_data)\n",
    "            target_train_labels.append(target_val)\n",
    "\n",
    "    target_train_data = pd.concat(target_train_data, ignore_index=True).astype(float)\n",
    "\n",
    "    return target_train_data, target_train_labels\n",
    "\n",
    "\n",
    "def evaluate_target(data, target_col: str, direction: str):\n",
    "    train_data, labels = prepare_temporal_data(data, target_col, direction)\n",
    "    assert target_col not in train_data.columns\n",
    "\n",
    "    def evaluate_clf(plugin, args={}):\n",
    "        model = plugin(**args)\n",
    "        encoded_labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "        return evaluate_estimator(model, train_data, pd.Series(encoded_labels))[\"clf\"][\n",
    "            \"aucroc\"\n",
    "        ][0]\n",
    "\n",
    "    def evaluate_reg(plugin, args={}):\n",
    "        model = plugin(**args)\n",
    "        return evaluate_regression(model, train_data, labels)[\"clf\"][\"r2\"][0]\n",
    "\n",
    "    best_score = -99\n",
    "    best_target_plugin = None\n",
    "    for (clf_type, reg_type) in [\n",
    "        (\"lgbm\", \"lgbm_regressor\"),\n",
    "        (\"xgboost\", \"xgboost_regressor\"),\n",
    "        (\"logistic_regression\", \"linear_regression\"),\n",
    "        (\"catboost\", \"catboost_regressor\"),\n",
    "        (\"random_forest\", \"random_forest_regressor\"),\n",
    "        (\"kneighbors\", \"kneighbors_regressor\"),\n",
    "    ]:\n",
    "        if len(np.unique(labels)) < cat_limit:\n",
    "            if clf_type is None:\n",
    "                continue\n",
    "            plugin = Classifiers().get_type(clf_type)\n",
    "            cbk = evaluate_clf\n",
    "        else:\n",
    "            if reg_type is None:\n",
    "                continue\n",
    "            plugin = Regression().get_type(reg_type)\n",
    "            cbk = evaluate_reg\n",
    "\n",
    "        study, pruner = create_study(\n",
    "            study_name=f\"long_imputation_{plugin.name()}_{target_col}_{direction}\",\n",
    "            direction=\"maximize\",\n",
    "            load_if_exists=True,\n",
    "        )\n",
    "\n",
    "        def objective(trial: optuna.Trial) -> float:\n",
    "            args = plugin.sample_hyperparameters(trial)\n",
    "            pruner.check_trial(trial)\n",
    "\n",
    "            try:\n",
    "                score = cbk(plugin, args)\n",
    "            except BaseException:\n",
    "                print(\"      failed evaluation\", plugin.name(), args)\n",
    "                return -5\n",
    "\n",
    "            # print(f\"    >>  {plugin.name()} {args} -> {score}\")\n",
    "            pruner.report_score(score)\n",
    "\n",
    "            return score\n",
    "\n",
    "        try:\n",
    "            study.optimize(objective, n_trials=100, timeout=60 * 10)\n",
    "        except EarlyStoppingExceeded:\n",
    "            pass\n",
    "\n",
    "        baseline_score = cbk(plugin)\n",
    "\n",
    "        if study.best_value > baseline_score:\n",
    "            score = study.best_value\n",
    "            args = study.best_trial.params\n",
    "        else:\n",
    "            score = baseline_score\n",
    "            args = {}\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_target_plugin, best_target_plugin_args = plugin, args\n",
    "\n",
    "    print(\n",
    "        f\"     >> Selected {target_col} --> {best_target_plugin.name()} -- {best_target_plugin_args}\",\n",
    "        best_score,\n",
    "    )\n",
    "\n",
    "    model = best_target_plugin(**best_target_plugin_args)\n",
    "\n",
    "    if len(np.unique(labels)) < cat_limit:\n",
    "        labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "    model.fit(train_data, labels)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_longitudinal_imputers(data, columns):\n",
    "    imputers = {}\n",
    "\n",
    "    for direction in [\"forward\", \"reverse\"]:\n",
    "        imputers[direction] = {}\n",
    "        for target_col in columns:\n",
    "            model = evaluate_target(data, target_col, direction=direction)\n",
    "\n",
    "            imputers[direction][target_col] = model\n",
    "\n",
    "    return imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3a9a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in eval_cols:\n",
    "#     evaluate_target(dev_set, col, direction = \"forward\")\n",
    "\n",
    "#      >> Selected DX_num --> xgboost -- {'reg_lambda': 8.962330859372681, 'reg_alpha': 8.608303558298164, 'colsample_bytree': 0.7745875968255177, 'colsample_bynode': 0.3990200802902815, 'colsample_bylevel': 0.8924327091878707, 'subsample': 0.8411533780703977, 'lr': 0.0001, 'max_depth': 3, 'n_estimators': 169, 'min_child_weight': 1, 'max_bin': 256, 'booster': 1} 0.9877047491583673\n",
    "#      >> Selected CDRSB --> linear_regression -- {'max_iter': 10000, 'solver': 1} 0.8235423012308886\n",
    "#      >> Selected MMSE --> xgboost_regressor -- {'reg_lambda': 2.1888371329742604, 'reg_alpha': 0.9312430343555846, 'max_depth': 2, 'n_estimators': 82, 'lr': 0.01} 0.7464127570286078\n",
    "#      >> Selected ADAS13 --> linear_regression -- {} 0.8184916603842121\n",
    "#      >> Selected Ventricles --> linear_regression -- {'max_iter': 100, 'solver': 1} 0.7916836168497275\n",
    "#      >> Selected Hippocampus --> xgboost_regressor -- {'reg_lambda': 1.664443906152452, 'reg_alpha': 0.11216371454959836, 'max_depth': 4, 'n_estimators': 59, 'lr': 0.0001} 0.8693374929967305\n",
    "#      >> Selected WholeBrain --> linear_regression -- {'max_iter': 10000, 'solver': 1} 0.892197332159023\n",
    "#      >> Selected Entorhinal --> linear_regression -- {} 0.7129676806181259\n",
    "#      >> Selected Fusiform --> linear_regression -- {'max_iter': 10000, 'solver': 1} 0.8196491882018542\n",
    "#      >> Selected MidTemp --> linear_regression -- {} 0.8511675281807548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "650a750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in eval_cols:\n",
    "#     evaluate_target(dev_set, col, direction = \"reverse\")\n",
    "\n",
    "\n",
    "#      >> Selected DX_num --> xgboost -- {'reg_lambda': 9.581894273376596, 'reg_alpha': 3.996895430038997, 'colsample_bytree': 0.41805003542171487, 'colsample_bynode': 0.8056647613216464, 'colsample_bylevel': 0.6632455401989068, 'subsample': 0.7898718692552386, 'lr': 0.0001, 'max_depth': 5, 'n_estimators': 224, 'min_child_weight': 0, 'max_bin': 503, 'booster': 1} 0.9834325918687735\n",
    "#      >> Selected CDRSB --> xgboost_regressor -- {'reg_lambda': 4.0066164445274195, 'reg_alpha': 5.238168400540354, 'max_depth': 2, 'n_estimators': 86, 'lr': 0.0001} 0.8143407597683612\n",
    "#      >> Selected MMSE --> xgboost_regressor -- {'reg_lambda': 6.668953586033021, 'reg_alpha': 0.690722830428056, 'max_depth': 2, 'n_estimators': 75, 'lr': 0.01} 0.7416617255780215\n",
    "#      >> Selected ADAS13 --> xgboost_regressor -- {'reg_lambda': 3.3543843807030633, 'reg_alpha': 0.5623126283166717, 'max_depth': 3, 'n_estimators': 78, 'lr': 0.0001} 0.8200312184647823\n",
    "#      >> Selected Ventricles --> linear_regression -- {'max_iter': 100, 'solver': 1} 0.7414274643766964\n",
    "#      >> Selected Hippocampus --> xgboost_regressor -- {'reg_lambda': 0.8716130833968974, 'reg_alpha': 0.6316607826045982, 'max_depth': 4, 'n_estimators': 100, 'lr': 0.0001} 0.8697211565809551\n",
    "#      >> Selected WholeBrain --> linear_regression -- {'max_iter': 100, 'solver': 1} 0.8917612746142106\n",
    "#      >> Selected Entorhinal --> linear_regression -- {'max_iter': 100, 'solver': 1} 0.7069076933758623\n",
    "#      >> Selected Fusiform --> linear_regression -- {'max_iter': 1000, 'solver': 1} 0.8207026292436043\n",
    "#      >> Selected MidTemp --> linear_regression -- {'max_iter': 1000, 'solver': 1} 0.8541884735250632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42823b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.utils.serialization import (load_model_from_file,\n",
    "                                             save_model_to_file)\n",
    "\n",
    "dev_set_id = dataframe_hash(dev_set)\n",
    "\n",
    "imputers_bkp_file = (\n",
    "    workspace\n",
    "    / f\"longitudinal_imputers_scaled_cat{cat_limit}_{dev_set_id}_automl_100.bkp\"\n",
    ")\n",
    "if imputers_bkp_file.exists():\n",
    "    longitudinal_imputers = load_model_from_file(imputers_bkp_file)\n",
    "else:\n",
    "    longitudinal_imputers = prepare_longitudinal_imputers(dev_set, eval_cols)\n",
    "    save_model_to_file(imputers_bkp_file, longitudinal_imputers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea254ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d28bbb23",
   "metadata": {},
   "source": [
    "## Static features imputation\n",
    "\n",
    "For the static features: [`PTGENDER_num`, `PTEDUCAT`, `APOE4`], we propagate the existing values for a patient to all the time points.\n",
    "\n",
    "For the `AGE` feature, we propagate the value using the \"VISCODE\" value. For observations `i` and `i + 1` for a patient, we use the formula\n",
    "```AGE[i + 1] = (VISCODE[i + 1] - VISCODE[i]) / 12 + AGE[i]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba3a927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "const_by_patient = [\"PTGENDER_num\", \"PTEDUCAT\", \"APOE4\"]\n",
    "\n",
    "\n",
    "def impute_consts(train_data, test_data):\n",
    "    \"\"\"For each patient, we fill the existing constant features to all time points.\"\"\"\n",
    "    test_data = test_data.copy()\n",
    "    train_data = train_data.copy()\n",
    "\n",
    "    train_data = train_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "    test_data = test_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "\n",
    "    for item in test_data.groupby(\"RID_HASH\"):\n",
    "        local = item[1]\n",
    "\n",
    "        # fill consts\n",
    "        for col in const_by_patient:\n",
    "            if len(local[col].unique()) == 1:\n",
    "                continue\n",
    "            rid = local[\"RID_HASH\"].unique()[0]\n",
    "\n",
    "            val = local[col][~local[col].isna()].unique()[0]\n",
    "            local[col] = local[col].fillna(val)\n",
    "            test_data.loc[test_data[\"RID_HASH\"] == rid, col] = test_data[\n",
    "                test_data[\"RID_HASH\"] == rid\n",
    "            ][col].fillna(val)\n",
    "            assert len(local[col].unique()) == 1, col\n",
    "\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def impute_age(train_data, test_data):\n",
    "    \"\"\"AGE imputation logic for each patient, based on VISCODE and the existing \"AGE\" values\n",
    "    For observations i and i + 1 for a patient,\n",
    "    AGE[i + 1] = (VISCODE[i + 1] - VISCODE[i]) / 12 + AGE[i]\n",
    "    \"\"\"\n",
    "    test_data = test_data.copy()\n",
    "    train_data = train_data.copy()\n",
    "\n",
    "    train_data = train_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "    test_data = test_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "\n",
    "    col = \"AGE\"\n",
    "\n",
    "    for rid in test_data[\"RID_HASH\"].unique():\n",
    "        local = test_data[test_data[\"RID_HASH\"] == rid]\n",
    "\n",
    "        # fill age\n",
    "        ages = local[\"AGE\"]\n",
    "        if ages.isna().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        if ages.isna().sum() == len(ages):\n",
    "            continue\n",
    "\n",
    "        # forward impute age\n",
    "        prev_viscode = 0\n",
    "        prev_age = 0\n",
    "        for idx, row in local.iterrows():\n",
    "            current_viscode = row[\"VISCODE\"]\n",
    "            local_idx = (test_data[\"VISCODE\"] == current_viscode) & (\n",
    "                test_data[\"RID_HASH\"] == rid\n",
    "            )\n",
    "            if prev_age > 0 and prev_age == prev_age:\n",
    "                pred_age = (current_viscode - prev_viscode) / 12 + prev_age\n",
    "            else:\n",
    "                pred_age = row[col]\n",
    "\n",
    "            if pred_age == pred_age:  # test not-NaN\n",
    "                # print(\"forward imputed\", pred_age, current_viscode)\n",
    "                test_data.loc[local_idx, col] = test_data.loc[local_idx][col].fillna(\n",
    "                    pred_age\n",
    "                )\n",
    "\n",
    "            prev_viscode = row[\"VISCODE\"]\n",
    "            prev_age = pred_age\n",
    "\n",
    "        # reverse impute age\n",
    "        prev_viscode = 0\n",
    "        prev_age = 0\n",
    "        for idx, row in local.iloc[::-1].iterrows():\n",
    "            current_viscode = row[\"VISCODE\"]\n",
    "            local_idx = (test_data[\"VISCODE\"] == current_viscode) & (\n",
    "                test_data[\"RID_HASH\"] == rid\n",
    "            )\n",
    "\n",
    "            if prev_age > 0 and prev_age == prev_age:\n",
    "                pred_age = prev_age - (prev_viscode - current_viscode) / 12\n",
    "            else:\n",
    "                pred_age = row[col]\n",
    "\n",
    "            if pred_age == pred_age:  # test not-NaN\n",
    "                # print(\"reversed imputed\", pred_age, current_viscode)\n",
    "                test_data.loc[local_idx, col] = test_data.loc[local_idx][col].fillna(\n",
    "                    pred_age\n",
    "                )\n",
    "\n",
    "            prev_viscode = row[\"VISCODE\"]\n",
    "            prev_age = pred_age\n",
    "\n",
    "        # print(test_data[(test_data[\"RID_HASH\"] == rid)][[\"VISCODE\", \"AGE\"]])\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda408fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4f85e7",
   "metadata": {},
   "source": [
    "## The complete imputation algorithm\n",
    "\n",
    "__Step 1.__ Impute the constants [`PTGENDER_num`, `PTEDUCAT`, `APOE4`] and the `AGE` from the existing observed data.\n",
    "\n",
    "__Step 2.__ Longitudinal imputation loop:\n",
    "\n",
    "        2.1 Create the intermediary imputation using ffill/bfill and HyperImpute. This is just a support for the longitudinal imputers to not deal with the missing values.\n",
    "        2.2 Run the longitudinal imputation for one step. For each column C with a missing value: if the value from the previous `VISCODE` was observed, we use the __forward__  longitudinal imputer to approximate it. If the value from the next `VISCODE` is observed, we use the __reverse__ longitudinal imputer. If both values are observed, we use both imputers and average their outputs.\n",
    "        2.3 If no value was imputed in the current step, exit the loop. Else, continue.\n",
    "        2.4 At this step, the missing features are completely unobserved for a patient. Otherwise, they would have been filled in the longitudinal loop. \n",
    "        \n",
    "__Step 3.__  We run the horizontal imputation to fill in the missing values.For each patient, we merge the horizontal imputation into the rows with the __least missing values__. We are not using the full horizontal imputation because it could miss some temporal patterns. Instead, we use it to seed a second longitudinal imputation loop. In particular, this step imputes all the patients with a single visit.\n",
    "\n",
    "__Step 4.__ Repeat the constant/AGE imputation with the new seed values from the horizontal imputation.\n",
    "\n",
    "__Step 5.__ Repeat the longitudinal loop and fill in the remaining missing values.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86035b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_longitudinal(\n",
    "    train_data: pd.DataFrame,\n",
    "    test_data: pd.DataFrame,\n",
    "    eval_cols: list = [\n",
    "        \"DX_num\",\n",
    "        \"CDRSB\",\n",
    "        \"MMSE\",\n",
    "        \"ADAS13\",\n",
    "        \"Ventricles\",\n",
    "        \"Hippocampus\",\n",
    "        \"WholeBrain\",\n",
    "        \"Entorhinal\",\n",
    "        \"Fusiform\",\n",
    "        \"MidTemp\",\n",
    "    ],\n",
    "):\n",
    "    \"\"\"Longitudinal imputation loop.\n",
    "\n",
    "    We fill the missing values with intermediary values using ffill/bfill, and HyperImpute, if needed.\n",
    "\n",
    "    For each patient, and for each missing value from column C:\n",
    "        - If the current patient has any observed value from column C, we use that for the longitudinal imputer from\n",
    "        the __forward__ or __reverse__ set(depending on the position related to the missing value).\n",
    "        - If both previous and next values are observed for a missing value, we use both longitudinal imputers,\n",
    "        and average their prediction.\n",
    "    \"\"\"\n",
    "    test_data = test_data.copy()\n",
    "    train_data = train_data.copy()\n",
    "\n",
    "    imputed_test_data = intermediary_imputation(train_data, test_data)\n",
    "\n",
    "    train_data = train_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "    test_data = test_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "    imputed_test_data = imputed_test_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "\n",
    "    prev_cols = [f\"prev_{col}\" for col in train_cols]\n",
    "\n",
    "    for rid in test_data[\"RID_HASH\"].unique():\n",
    "        patient = test_data[test_data[\"RID_HASH\"] == rid]\n",
    "        patient_imputed = imputed_test_data[imputed_test_data[\"RID_HASH\"] == rid]\n",
    "\n",
    "        prediction_rows = [pd.Series(np.zeros(len(prev_cols)), index=train_cols)]\n",
    "        for ridx, row in patient.iterrows():\n",
    "            prediction_rows.append(row[train_cols])\n",
    "        prediction_rows.append(pd.Series(np.zeros(len(prev_cols)), index=train_cols))\n",
    "\n",
    "        for col in eval_cols:\n",
    "            if patient[col].isna().sum() == 0:\n",
    "                continue\n",
    "\n",
    "            for ridx, row in enumerate(prediction_rows[1:-1]):\n",
    "                real_idx = ridx + 1\n",
    "                if row[col] == row[col]:\n",
    "                    continue\n",
    "                current_viscode = row[\"VISCODE\"]\n",
    "                local_idx = (test_data[\"VISCODE\"] == current_viscode) & (\n",
    "                    test_data[\"RID_HASH\"] == rid\n",
    "                )\n",
    "\n",
    "                prev_col_val = prediction_rows[real_idx - 1][col]\n",
    "                next_col_val = prediction_rows[real_idx + 1][col]\n",
    "\n",
    "                if next_col_val == next_col_val and ridx + 1 < len(patient_imputed):\n",
    "                    eval_data = (\n",
    "                        patient_imputed.iloc[ridx].to_frame().T[train_cols]\n",
    "                    ).drop(\n",
    "                        columns=[col]\n",
    "                    )  # row.to_frame().T[train_cols]\n",
    "                    eval_data[prev_cols] = (\n",
    "                        patient_imputed.iloc[ridx + 1].to_frame().T[train_cols].values\n",
    "                    )\n",
    "                    eval_data = eval_data.astype(float)\n",
    "\n",
    "                    assert eval_data.isna().sum().sum() == 0\n",
    "                    assert eval_data[f\"prev_{col}\"].values[0] == next_col_val\n",
    "\n",
    "                    imputer = longitudinal_imputers[\"reverse\"][col]\n",
    "                    imputed_val = imputer.predict(eval_data).values.squeeze()\n",
    "\n",
    "                    test_data.loc[local_idx, col] = imputed_val\n",
    "\n",
    "                if prev_col_val == prev_col_val and ridx > 0:\n",
    "                    # print(\"Imputing using the prev value\", prev_col_val)\n",
    "                    eval_data = (\n",
    "                        patient_imputed.iloc[ridx].to_frame().T[train_cols]\n",
    "                    ).drop(columns=[col])\n",
    "                    eval_data[prev_cols] = (\n",
    "                        patient_imputed.iloc[ridx - 1].to_frame().T[train_cols].values\n",
    "                    )\n",
    "                    eval_data = eval_data.astype(float)\n",
    "\n",
    "                    assert eval_data.isna().sum().sum() == 0\n",
    "                    assert eval_data[f\"prev_{col}\"].values[0] == prev_col_val\n",
    "\n",
    "                    imputer = longitudinal_imputers[\"forward\"][col]\n",
    "                    imputed_val = imputer.predict(eval_data).values.squeeze()\n",
    "\n",
    "                    existing_value = test_data.loc[local_idx, col].values[0]\n",
    "                    if existing_value == existing_value:\n",
    "                        imputed_val = (imputed_val + existing_value) / 2\n",
    "                    test_data.loc[local_idx, col] = imputed_val\n",
    "\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def intermediary_imputation(train_data, test_data, forward_first=True):\n",
    "    \"\"\"Helper for the longitudinal imputation.\n",
    "    We use it to fill the missing values using the previous(ffill), or future values(bfill).\n",
    "    If a feature is completely missing, we fill it using Hyperimpute.\n",
    "\n",
    "    This imputated dataset it is used only as a backbone for the longitudinal imputation,\n",
    "    and it is not used in the final results.\n",
    "    \"\"\"\n",
    "    test_data = test_data.copy()\n",
    "\n",
    "    for rid in test_data[\"RID_HASH\"].unique():\n",
    "        local = test_data[test_data[\"RID_HASH\"] == rid]\n",
    "\n",
    "        if forward_first:\n",
    "            local = local.ffill().bfill()\n",
    "        else:\n",
    "            local = local.bfill().ffill()\n",
    "\n",
    "        test_data.loc[test_data[\"RID_HASH\"] == rid] = local\n",
    "\n",
    "    test_data = impute_consts(train_data, test_data)\n",
    "    test_data = impute_age(train_data, test_data)\n",
    "    return horizontal_imputation(train_data, test_data)\n",
    "\n",
    "\n",
    "def merge_static_imputation(train_data, test_data, static_imputation):\n",
    "    \"\"\"Given a static imputation from HyperImpute, for each patient:\n",
    "        - We select the row with the least missing values.\n",
    "        - We impute that row with the values from the static imputation output.\n",
    "\n",
    "    This is useful for features that are completery missing for a patient.\n",
    "    We fill only one row, and let the longitudinal imputers fill the rest.\n",
    "    \"\"\"\n",
    "    test_data = test_data.copy()\n",
    "    train_data = train_data.copy()\n",
    "\n",
    "    train_data = train_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "    test_data = test_data.sort_values([\"RID_HASH\", \"VISCODE\"])\n",
    "\n",
    "    for rid in test_data[\"RID_HASH\"].unique():\n",
    "        patient = test_data[test_data[\"RID_HASH\"] == rid]\n",
    "        misses = []\n",
    "        viscodes = []\n",
    "        for idx, row in patient.iterrows():\n",
    "            misses.append(row.isna().sum())\n",
    "            viscodes.append(row[\"VISCODE\"])\n",
    "        cidx = np.argmin(misses)\n",
    "\n",
    "        current_viscode = viscodes[cidx]\n",
    "        local_idx = (test_data[\"VISCODE\"] == current_viscode) & (\n",
    "            test_data[\"RID_HASH\"] == rid\n",
    "        )\n",
    "        imputed_idx = (static_imputation[\"VISCODE\"] == current_viscode) & (\n",
    "            static_imputation[\"RID_HASH\"] == rid\n",
    "        )\n",
    "\n",
    "        if len(test_data[local_idx]) == 0:\n",
    "            continue\n",
    "\n",
    "        for col in test_data.columns:\n",
    "            val = test_data.loc[local_idx][col].values[0]\n",
    "            if val == val:\n",
    "                continue\n",
    "            imputed_val = static_imputation.loc[imputed_idx][col].values[0]\n",
    "            test_data.loc[local_idx, col] = imputed_val\n",
    "\n",
    "            # print(\"imputed\", test_data.loc[local_idx, col])\n",
    "\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def impute_data(train_data, test_data):\n",
    "    \"\"\"Main imputation loop.\n",
    "\n",
    "    Steps:\n",
    "\n",
    "    1. Impute constant and AGE features.\n",
    "    2. Longitudinal imputation loop:\n",
    "        2.1 Create the intermediary imputation.\n",
    "        2.2 Run the longitudinal imputation for one step.\n",
    "        2.3 If no value was imputation in the current step, exit the loop. Else, continue.\n",
    "    3. Create the static imputation of the remaining missing values.\n",
    "    4. For each patient, merge the static imputation into the row with the least missing values.\n",
    "    In particular, this step imputes all the patients with a single visit.\n",
    "    5. Repeat the constant/AGE imputation with the new seed values from the static imputation.\n",
    "    6. Repeat the longitudinal loop and fill the remaining missing values.\n",
    "\n",
    "    \"\"\"\n",
    "    test_id = dataframe_hash(test_data)\n",
    "    train_id = dataframe_hash(train_data)\n",
    "\n",
    "    print(\"Evaluate constants\", test_id, test_data.isna().sum().sum())\n",
    "    test_data = impute_consts(train_data, test_data)\n",
    "    test_data = impute_age(train_data, test_data)\n",
    "\n",
    "    while True:\n",
    "        print(\"Evaluate longitudinals\", test_id, test_data.isna().sum().sum())\n",
    "        new_test_data = impute_longitudinal(train_data, test_data)\n",
    "        if new_test_data.isna().sum().sum() == test_data.isna().sum().sum():\n",
    "            break\n",
    "\n",
    "        test_data = new_test_data\n",
    "\n",
    "    print(\n",
    "        \"Evaluate static imputation\",\n",
    "        test_id,\n",
    "        test_data.isna().sum().sum(),\n",
    "    )\n",
    "    static_imputation = horizontal_imputation(train_data, test_data)\n",
    "\n",
    "    test_data = merge_static_imputation(train_data, test_data, static_imputation)\n",
    "\n",
    "    print(\"Evaluate constants take 2\", test_id, test_data.isna().sum().sum())\n",
    "    test_data = impute_consts(train_data, test_data)\n",
    "    test_data = impute_age(train_data, test_data)\n",
    "\n",
    "    while True:\n",
    "        print(\"Evaluate longitudinals take 2\", test_id, test_data.isna().sum().sum())\n",
    "        new_test_data = impute_longitudinal(train_data, test_data)\n",
    "        if new_test_data.isna().sum().sum() == test_data.isna().sum().sum():\n",
    "            break\n",
    "\n",
    "        test_data = new_test_data\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e940b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.utils.benchmarks import RMSE\n",
    "\n",
    "\n",
    "def eval_training_error(train_data, test_data):\n",
    "    \"\"\"Helper for benchmarking the imputation\"\"\"\n",
    "    imputed = impute_data(train_data, test_data)\n",
    "    mask = test_data.isna().astype(int)\n",
    "\n",
    "    return RMSE(\n",
    "        imputed.drop(columns=[\"RID_HASH\"]).values,\n",
    "        train_data.drop(columns=[\"RID_HASH\"]).values,\n",
    "        mask.drop(columns=[\"RID_HASH\"]).values,\n",
    "    )\n",
    "\n",
    "\n",
    "eval_training_error(dev_set, dev_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c013f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_training_error(dev_set, dev_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b1f0f",
   "metadata": {},
   "source": [
    "## Submission data\n",
    "\n",
    "For the final submission data, we concatenate test_A and test_B, and impute them.\n",
    "\n",
    "This is because both may contain fully observed data, which can be used next to the training set for selecting/training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_AB = pd.concat([dev_set, test_A, test_B], ignore_index=True)\n",
    "\n",
    "test_AB_imputed = impute_data(dev_set, test_AB)\n",
    "test_AB_imputed[scaled_cols] = scaler.inverse_transform(test_AB_imputed[scaled_cols])\n",
    "\n",
    "test_AB_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "def normalize_output(test_data):\n",
    "    \"\"\"Normalize the feature for the final submission.\"\"\"\n",
    "    test_data = test_data.copy()\n",
    "\n",
    "    factor = test_data[\"CDRSB\"] / 0.5\n",
    "    factor[factor < 0] = 0\n",
    "    factor = factor.fillna(-1)\n",
    "    factor = factor.round(0).astype(int)\n",
    "    factor = factor.replace(-1, np.nan)\n",
    "    test_data[\"CDRSB\"] = factor * 0.5\n",
    "\n",
    "    test_data[\"DX_num\"] = test_data[\"DX_num\"].round(0)\n",
    "\n",
    "    test_data[\"ADAS13\"] = ((test_data[\"ADAS13\"] * 3).round(0) / 3).round(2)\n",
    "    test_data[\"MMSE\"] = test_data[\"MMSE\"].round(0)\n",
    "\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def dump_results(imputed_data: pd.DataFrame, fpath: str):\n",
    "    \"\"\"Create the submission file\"\"\"\n",
    "    for name, data in [\n",
    "        (\"test_A\", test_A),\n",
    "        (\"test_B\", test_B),\n",
    "    ]:\n",
    "        for idx, row in data.iterrows():\n",
    "            for col in row.index:\n",
    "                local = row.T\n",
    "                val = local[col]\n",
    "                if val == val:\n",
    "                    continue\n",
    "                imputed_id = f\"{local['RID_HASH']}_{local['VISCODE']}_{col}_{name}\"\n",
    "                imputed_val = imputed_data[\n",
    "                    (imputed_data[\"RID_HASH\"] == local[\"RID_HASH\"])\n",
    "                    & (imputed_data[\"VISCODE\"] == local[\"VISCODE\"])\n",
    "                ][col].values[0]\n",
    "\n",
    "                assert imputed_val == imputed_val\n",
    "                assert imputed_val != \"\"\n",
    "\n",
    "                results.append([imputed_id, imputed_val])\n",
    "\n",
    "    output = pd.DataFrame(results, columns=submission.columns)\n",
    "    output.to_csv(fpath, index=None)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "output_normalized = dump_results(\n",
    "    normalize_output(test_AB_imputed),\n",
    "    results_dir / f\"submission.csv\",\n",
    ")\n",
    "\n",
    "output_normalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
